# Comprehensive Code Review: rec_to_nwb_yaml_creator & trodes_to_nwb Integration

**Review Date:** 2025-01-23
**Reviewer:** Senior Developer (AI Assistant)
**Scope:** Full codebase review with focus on data quality, integration, and user error prevention

---

## Executive Summary

This review analyzes both `rec_to_nwb_yaml_creator` (React web app) and `trodes_to_nwb` (Python package) as an integrated system for neuroscience data conversion. The system is **critical infrastructure** for converting SpikeGadgets electrophysiology data to NWB format for DANDI archive submission.

### Overall Assessment

**rec_to_nwb_yaml_creator:** ‚ö†Ô∏è **MODERATE RISK**

- 49 issues identified (6 Critical, 16 High, 18 Medium, 9 Low)
- Primary concerns: Data validation gaps, state management issues, integration synchronization risks

**trodes_to_nwb:** ‚ö†Ô∏è **MODERATE RISK**

- 42 issues identified (4 Critical, 13 High, 19 Medium, 6 Low)
- Primary concerns: Error handling inconsistency, late validation, unclear error messages

**Integration:** üî¥ **HIGH RISK**

- No automated schema synchronization
- Device type mismatch risks
- Validation differences between JavaScript (AJV) and Python (jsonschema)

### Database Context: Spyglass Integration

The NWB files generated by this pipeline are ultimately ingested into the **[Spyglass](https://github.com/LorenFrankLab/spyglass)** database system, which uses DataJoint to manage neuroscience experimental data. Understanding this downstream consumer is **critical for data consistency**.

**Key Database Tables Consuming NWB Metadata:**

- **Session** - Extracts `session_id`, `session_description`, `session_start_time`, experimenter names
- **ElectrodeGroup** - Maps electrode groups to `BrainRegion` and `Probe` entries
- **Electrode** - Individual electrodes with coordinates, filtering, impedance from ndx_franklab_novela extension
- **Probe** - Pre-registered probe configurations (must exist before ingestion)
- **DataAcquisitionDevice** - Hardware devices validated against existing DB entries

**Critical Failure Points:**

1. **Undefined `probe_type`** - ElectrodeGroup.probe_id becomes NULL if probe not pre-registered ‚Üí **Data Loss**
2. **Missing ndx_franklab_novela columns** - `bad_channel`, `probe_shank`, `probe_electrode`, `ref_elect_id` missing causes warnings and incomplete data
3. **NULL electrode_group.location** - Creates "Unknown" brain region, breaking spatial queries
4. **Device metadata divergence** - NWB device properties that differ from DB trigger PopulateException unless manually approved
5. **Inconsistent brain region names** - Location strings like "CA1", "ca1", "Ca1" create duplicate BrainRegion entries

**Naming Consistency Requirements:**

- `electrode_group.location` ‚Üí Auto-creates `BrainRegion` entries; variations cause duplicates
- `electrode_group.device.probe_type` ‚Üí Must exactly match existing `Probe.probe_id` (case-sensitive)
- `electrode_group_name` ‚Üí Must exactly match NWB electrode_groups dictionary keys

**Recommendation:** The web app should validate `probe_type` against the Spyglass Probe table (or provide a sync mechanism) and enforce controlled vocabularies for brain regions to prevent database fragmentation.

### Critical Spyglass Database Constraints

**Entry Point:** `spyglass/src/spyglass/data_import/insert_sessions.py::insert_sessions()`

#### VARCHAR Length Limits (Immediate Ingestion Failures)

| Field | MySQL Limit | Current Validation | Impact |
|-------|------------|-------------------|--------|
| **nwb_file_name** | 64 bytes | ‚ùå None | üî¥ CRITICAL: Entire ingestion fails |
| **interval_list_name** | 170 bytes | ‚ùå None | üî¥ CRITICAL: TaskEpoch insert fails |
| electrode_group_name | 80 bytes | ‚ùå None | üü° HIGH: ElectrodeGroup insert fails |
| subject_id | 80 bytes | ‚ùå None | üü° HIGH: Session insert fails |

**Example Failure:**

```python
# Generated filename (from web app):
filename = "20250123_subject_with_long_descriptive_name_and_details_metadata.yml"
# Length: 69 characters ‚Üí EXCEEDS 64 byte limit

# Result in Spyglass:
# DataJointError: Data too long for column 'nwb_file_name' at row 1
# ENTIRE SESSION ROLLBACK - All work lost
```

**Fix Required in Web App:**

```javascript
// Before YAML download
function validateFilename(date, subject_id) {
  const filename = `${date}_${subject_id}_metadata.yml`;

  if (filename.length > 64) {
    throw new Error(
      `Filename too long (${filename.length} chars, max 64).\n\n` +
      `Current: ${filename}\n\n` +
      `Please shorten subject_id to ${64 - date.length - 14} characters or less.`
    );
  }
}
```

#### NOT NULL & Non-Empty String Constraints

| Field | Database Requirement | Current Schema | Bug |
|-------|---------------------|---------------|-----|
| session_description | NOT NULL AND length > 0 | ‚úÖ Required | ‚ùå Allows empty string |
| electrode_group.description | NOT NULL AND length > 0 | ‚úÖ Required | ‚ùå Allows empty string |
| electrode.filtering | NOT NULL | ‚ùå Not in schema | üî¥ Missing field |

**Current Bug:**

```yaml
# YAML passes validation:
session_description: ""

# Spyglass rejects:
# IntegrityError: Column 'session_description' cannot be null or empty
```

**Fix Required in Schema:**

```json
{
  "session_description": {
    "type": "string",
    "minLength": 1,  // Add this constraint
    "description": "Brief description of session (must be non-empty)"
  },
  "electrode_groups": {
    "items": {
      "properties": {
        "description": {
          "type": "string",
          "minLength": 1  // Add this
        },
        "filtering": {  // Add this missing field
          "type": "string",
          "description": "Filter settings (e.g., '0-9000 Hz')",
          "default": "0-30000 Hz"
        }
      }
    }
  }
}
```

#### Global Uniqueness Constraints (Cross-Session)

These fields **must be unique across ALL sessions** in the entire database:

| Field | Scope | Collision Impact | Current Protection |
|-------|-------|-----------------|-------------------|
| subject_id | **Global** | Same ID = same animal; conflicts corrupt metadata | ‚ùå None |
| task_name | **Global** | "Task Divergence" error if properties differ | ‚ùå None |
| nwb_file_name | **Global** | Duplicate filename fails unique constraint | ‚ùå None |

**Critical Issue - Subject ID Case Sensitivity:**

Spyglass performs case-insensitive comparison but **doesn't normalize during entry**:

```yaml
# User A (Lab Member 1):
subject_id: "Mouse1"
date_of_birth: "2024-01-15"

# User B (Lab Member 2, different mouse):
subject_id: "mouse1"  # Thinks it's different
date_of_birth: "2024-03-20"

# Database Query:
SELECT * FROM Session WHERE LOWER(subject_id) = 'mouse1'
# Returns BOTH sessions

# Result: Same subject with conflicting birth dates ‚Üí DATA CORRUPTION
```

**Fix Required:**

```javascript
// Enforce lowercase-only pattern
const SUBJECT_ID_PATTERN = /^[a-z][a-z0-9_]*$/;

function validateSubjectId(value) {
  if (!SUBJECT_ID_PATTERN.test(value)) {
    const normalized = value.toLowerCase().replace(/[^a-z0-9_]/g, '_');
    return {
      valid: false,
      error: "Subject ID must start with lowercase letter, contain only lowercase letters, numbers, underscores",
      suggestion: normalized
    };
  }

  // TODO: Check against Spyglass API for existing subjects
  // For now, show strong warning:
  return {
    valid: true,
    warning: `‚ö†Ô∏è Ensure "${value}" is globally unique for this subject across all experiments.\n` +
             `Using same ID for different animals causes database corruption.`
  };
}
```

#### Enum Value Constraints (Silent Data Corruption)

| Field | Valid Values | Invalid Behavior | Current Validation |
|-------|-------------|-----------------|-------------------|
| **sex** | 'M', 'F', 'U' ONLY | Silently converts to 'U' | ‚ùå Allows any string |
| species | Latin names (controlled vocab) | Accepts anything | ‚ùå Free text |

**Current Bug:**

```yaml
subject:
  sex: "Male"  # Looks valid to user

# Spyglass ingestion:
if sex not in ['M', 'F', 'U']:
    sex = 'U'  # Silent conversion

# Result: User thinks sex is "Male", database stores "U" (Unknown)
# NO ERROR MESSAGE - user never knows data was corrupted
```

**Fix Required:**

```json
{
  "sex": {
    "type": "string",
    "enum": ["M", "F", "U"],
    "description": "Sex: M (male), F (female), U (unknown/other)"
  }
}
```

**Web App UI:**

```javascript
// Use radio buttons or strict dropdown, NOT free text
<RadioList
  options={[
    { value: 'M', label: 'Male' },
    { value: 'F', label: 'Female' },
    { value: 'U', label: 'Unknown' }
  ]}
  required={true}
/>
```

#### Foreign Key Insertion Order (Transaction Failures)

Spyglass inserts in **strict order** with **automatic rollback on any failure**:

**Transaction 1 (Atomic Block):**

1. Session
2. ElectrodeGroup ‚Üí **requires** BrainRegion (auto-created from `location` field)
3. TaskEpoch ‚Üí **requires** interval_list_name ‚â§ 170 chars
4. DIOEvents

**If ANY step fails ‚Üí Complete rollback, no partial data saved**

**Transaction 2:**

1. Electrode ‚Üí **requires** existing ElectrodeGroup
2. VideoFile ‚Üí **requires** existing CameraDevice
3. PositionSource

**Critical Dependencies:**

| NWB Field | Database Table | Foreign Key Constraint |
|-----------|---------------|----------------------|
| electrode_group_name | ElectrodeGroup | Must exactly match nwbfile.electrode_groups keys (case-sensitive) |
| camera_name | VideoFile | Must match registered CameraDevice.camera_name |
| task_name | Task | Checked for property divergence across sessions |
| location | ElectrodeGroup.brain_region_id | Auto-creates BrainRegion if needed |

**Example Failure:**

```python
# In NWB file:
nwbfile.electrode_groups['0']  # Group name is string "0"

# In YAML metadata:
electrode_groups:
  - id: 0  # Integer

# In electrodes table:
group_name = str(electrode_group_id)  # = "0"

# Spyglass foreign key check:
SELECT * FROM ElectrodeGroup WHERE electrode_group_name = '0'  # Success

# But if YAML had:
electrode_group_name: "Tetrode 1"  # Different from ID

# Query:
SELECT * FROM ElectrodeGroup WHERE electrode_group_name = 'Tetrode 1'
# Fails if NWB used ID "0" as key ‚Üí FOREIGN KEY CONSTRAINT VIOLATION
```

### Required Web App Changes for Spyglass Compatibility

**P0 - Prevents Ingestion Failure (Immediate):**

- [ ] ‚úÖ Validate nwb_file_name length ‚â§ 64 bytes (calculate during download)
- [ ] ‚úÖ Validate interval_list_name ‚â§ 170 bytes (from task epoch tags)
- [ ] ‚úÖ Enforce `session_description` minLength: 1 (non-empty string)
- [ ] ‚úÖ Enforce `electrode_group.description` minLength: 1
- [ ] ‚úÖ Add `filtering` field to electrode schema (required by Spyglass Electrode table)
- [ ] ‚úÖ Validate electrode_group_name matches NWB key exactly (case-sensitive)

**P1 - Prevents Data Corruption (High Priority):**

- [ ] ‚úÖ Enforce sex enum: ["M", "F", "U"] ONLY (replace free text with radio/dropdown)
- [ ] ‚úÖ Enforce subject_id pattern: `^[a-z][a-z0-9_]*$` (lowercase, alphanumeric, underscore)
- [ ] ‚úÖ Warn on potential duplicate subject_id (ideally query Spyglass API)
- [ ] ‚úÖ Validate task_name uniqueness (or warn about property divergence)
- [ ] ‚úÖ Enforce species controlled vocabulary (Latin names from approved list)

**P2 - Improves Data Quality (Medium Priority):**

- [ ] ‚úÖ BrainRegion controlled vocabulary for electrode_group.location (prevent "CA1"/"ca1" duplicates)
- [ ] ‚úÖ Electrode coordinate numeric validation (reject strings, validate ranges)
- [ ] ‚úÖ Epoch timestamp validation (start_time < stop_time)
- [ ] ‚úÖ Electrode ID contiguity checking

---

## üî¥ HIGHEST PRIORITY ISSUES

These issues pose the greatest risk to data quality and must be addressed immediately:

### 1. DATA CORRUPTION: Date of Birth Validation Bug (CRITICAL)

**Repository:** trodes_to_nwb
**Location:** `src/trodes_to_nwb/metadata_validation.py:64`
**Impact:** üî¥ **Data Corruption - All Users Affected**

```python
# CURRENT (WRONG):
metadata_content["subject"]["date_of_birth"] = (
    metadata_content["subject"]["date_of_birth"].utcnow().isoformat()
)
# This OVERWRITES the actual birth date with the current time!
```

**Fix:**

```python
# CORRECT:
if isinstance(metadata_content["subject"]["date_of_birth"], datetime.datetime):
    metadata_content["subject"]["date_of_birth"] = (
        metadata_content["subject"]["date_of_birth"].isoformat()
    )
```

**Why Critical:** Every conversion corrupts the date of birth field, making all NWB files inaccurate.

---

### 2. SCHEMA DRIFT: No Automated Synchronization (CRITICAL)

**Repositories:** Both
**Location:** `nwb_schema.json` in both repos
**Impact:** üî¥ **Silent Failures - Data Loss**

**Problem:** The two repositories maintain separate copies of `nwb_schema.json` with no automated verification they match. Schema changes in one repo don't automatically propagate to the other.

**Current State:**

```
rec_to_nwb_yaml_creator/src/nwb_schema.json  ‚Üê‚Üí  Manual sync  ‚Üê‚Üí  trodes_to_nwb/src/trodes_to_nwb/nwb_schema.json
```

**Consequences:**

1. YAML created by web app passes validation
2. Python package rejects same YAML with cryptic errors
3. Users lose work and trust in the system

**Solutions (Pick One):**

**Option A - Shared NPM Package (Recommended):**

```bash
# Create new repo: nwb-schema-definitions
# Publish to npm
npm publish @lorenfranklab/nwb-schema

# In rec_to_nwb_yaml_creator:
npm install @lorenfranklab/nwb-schema
import schema from '@lorenfranklab/nwb-schema/nwb_schema.json'

# In trodes_to_nwb:
pip install nwb-schema  # Python package wrapper
```

**Option B - CI Check (Quick Fix):**

```yaml
# .github/workflows/schema-sync-check.yml
name: Schema Sync Check
on: [pull_request]
jobs:
  check-schema:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Compare schemas
        run: |
          curl -o remote_schema.json https://raw.githubusercontent.com/LorenFrankLab/trodes_to_nwb/main/src/trodes_to_nwb/nwb_schema.json
          diff -u src/nwb_schema.json remote_schema.json || {
            echo "‚ùå Schema mismatch detected!"
            echo "Update schema in both repositories"
            exit 1
          }
```

---

### 3. SILENT VALIDATION FAILURES (CRITICAL)

**Repository:** rec_to_nwb_yaml_creator
**Location:** `src/App.js` (multiple locations)
**Impact:** üî¥ **Users Unknowingly Create Invalid Data**

**Problem:** Validation only runs on form submission. Users can:

- Work for 30+ minutes filling complex forms
- Have invalid data throughout (IDs, cameras, epochs)
- Discover errors only at the end
- Lose motivation and create workarounds

**Example:**

```javascript
// User enters duplicate electrode group IDs
<InputElement id="electrode_groups-id-0" defaultValue={0} />
<InputElement id="electrode_groups-id-1" defaultValue={0} />  // DUPLICATE!
// ‚úó No warning until "Generate YAML" clicked
```

**Fix - Progressive Validation:**

```javascript
const [validationState, setValidationState] = useState({
  subject: { valid: false, errors: [] },
  electrode_groups: { valid: false, errors: [] },
  // ... per section
});

// Real-time validation
const validateElectrodeGroupId = (id, index, allGroups) => {
  const duplicates = allGroups.filter(g => g.id === id);
  if (duplicates.length > 1) {
    return {
      valid: false,
      error: `Electrode group ID ${id} is used ${duplicates.length} times. IDs must be unique.`
    };
  }
  return { valid: true };
};

// Visual feedback
<div className="section-status">
  {validationState.electrode_groups.valid ? '‚úì' : '‚ö†Ô∏è'} Electrode Groups
</div>
```

---

### 4. DEVICE TYPE MISMATCH TRAP (CRITICAL)

**Repositories:** Both
**Impact:** üî¥ **Conversion Failures After YAML Creation**

**Problem:** Web app has hardcoded device types. No verification that probe metadata exists in trodes_to_nwb.

**Failure Scenario:**

```
1. User selects "custom_probe_64ch" from web app dropdown
2. YAML generated successfully with device_type: "custom_probe_64ch"
3. User runs trodes_to_nwb conversion
4. ERROR: "No probe metadata found for custom_probe_64ch"
5. User must:
   - Edit YAML manually (error-prone)
   - OR recreate in web app (time wasted)
   - OR add probe metadata to trodes_to_nwb (complex)
```

**Fix:**

**Web App (`valueList.js`):**

```javascript
// Add documentation
export const deviceTypes = () => {
  return [
    'tetrode_12.5',
    'A1x32-6mm-50-177-H32_21mm',
    '128c-4s8mm6cm-20um-40um-sl',
    '128c-4s6mm6cm-15um-26um-sl',
    '32c-2s8mm6cm-20um-40um-dl',
    '64c-4s6mm6cm-20um-40um-dl',
    '64c-3s6mm6cm-20um-40um-sl',
    'NET-EBL-128ch-single-shank',
  ];
};

// IMPORTANT: Each device_type must have a corresponding probe metadata file in:
// trodes_to_nwb/src/trodes_to_nwb/device_metadata/probe_metadata/{device_type}.yml
```

**Python Package (`convert_yaml.py:205-214`):**

```python
available_types = [m.get("probe_type") for m in probe_metadata]
probe_meta = None
for test_meta in probe_metadata:
    if test_meta.get("probe_type") == egroup_metadata["device_type"]:
        probe_meta = test_meta
        break

if probe_meta is None:
    raise ValueError(
        f"Unknown device_type '{egroup_metadata['device_type']}' for electrode group {egroup_metadata['id']}.\n\n"
        f"Available probe types:\n" +
        "\n".join(f"  - {t}" for t in sorted(available_types)) +
        f"\n\nTo fix:\n"
        f"1. Check your YAML file's electrode_groups section\n"
        f"2. Use one of the available probe types listed above\n"
        f"3. OR add a probe metadata file: device_metadata/probe_metadata/{egroup_metadata['device_type']}.yml\n"
        f"4. See documentation: https://github.com/LorenFrankLab/trodes_to_nwb#adding-probe-types"
    )
```

---

### 5. HARDWARE CHANNEL VALIDATION GAPS (CRITICAL)

**Repository:** trodes_to_nwb
**Location:** `src/trodes_to_nwb/convert_rec_header.py`
**Impact:** üî¥ **Silent Data Corruption**

**Problem:** Channel mapping validation doesn't check:

- Duplicate channel assignments
- Channel IDs within valid ranges
- All expected channels mapped
- Channel map keys are valid

**Example of Silent Corruption:**

```yaml
# YAML has duplicate mapping:
ntrode_electrode_group_channel_map:
  - ntrode_id: 1
    map:
      "0": 5  # Maps to electrode 5
      "1": 5  # DUPLICATE! Also maps to 5
      "2": 7
      "3": 8
# ‚úó Validation passes
# ‚úó Conversion succeeds
# ‚úó Data from channels 0 and 1 both written to electrode 5
# ‚úó User doesn't discover until analysis phase
```

**Fix:**

```python
def validate_channel_map(channel_map: dict, ntrode_id: int, hw_config) -> None:
    """Validate channel map integrity."""
    mapped_electrodes = set()
    mapped_hw_channels = set()

    for config_ch, nwb_electrode in channel_map["map"].items():
        # Check for duplicate electrode assignments
        if nwb_electrode in mapped_electrodes:
            raise ValueError(
                f"Ntrode {ntrode_id}: Electrode {nwb_electrode} mapped multiple times. "
                f"Each electrode can only be mapped to one channel."
            )
        mapped_electrodes.add(nwb_electrode)

        # Check hardware channel validity
        hw_chan = hw_config[int(config_ch)]["hwChan"]
        if hw_chan in mapped_hw_channels:
            raise ValueError(
                f"Ntrode {ntrode_id}: Hardware channel {hw_chan} used multiple times. "
                f"Check for mapping errors."
            )
        mapped_hw_channels.add(hw_chan)

    # Verify all channels mapped
    expected_count = len(hw_config)
    if len(channel_map["map"]) != expected_count:
        raise ValueError(
            f"Ntrode {ntrode_id}: Expected {expected_count} channel mappings, "
            f"found {len(channel_map['map'])}"
        )
```

---

### 6. TYPE COERCION BUG: Camera IDs Accept Floats (CRITICAL)

**Repository:** rec_to_nwb_yaml_creator
**Location:** `src/App.js:217-237`
**Impact:** üî¥ **Invalid Data Accepted**

**Problem:**

```javascript
// Camera ID input uses type="number"
<InputElement
  id="cameras-id-0"
  type="number"  // Allows 1.5, 2.7, etc.
  name="id"
/>

// onBlur handler uses parseFloat for ALL numbers
const onBlur = (e, metaData) => {
  inputValue = type === 'number' ? parseFloat(value, 10) : value;  // WRONG!
};

// Result: User enters "1.5" as camera ID ‚Üí accepted ‚Üí conversion fails
```

**Fix:**

```javascript
const onBlur = (e, metaData) => {
  const { target } = e;
  const { name, value, type } = target;
  const { key, index, isInteger, isCommaSeparatedStringToNumber, isCommaSeparatedString } = metaData || {};

  let inputValue = '';

  if (isCommaSeparatedString) {
    inputValue = formatCommaSeparatedString(value);
  } else if (isCommaSeparatedStringToNumber) {
    inputValue = commaSeparatedStringToNumber(value);
  } else if (type === 'number') {
    // Determine if field should be integer or float
    const integerFields = ['id', 'ntrode_id', 'electrode_group_id', 'camera_id', 'task_epochs'];
    const isIntegerField = integerFields.some(field => name.includes(field)) || isInteger;

    if (isIntegerField) {
      const parsed = parseInt(value, 10);
      if (isNaN(parsed)) {
        showCustomValidityError(target, `${name} must be a whole number`);
        return;
      }
      inputValue = parsed;
    } else {
      inputValue = parseFloat(value, 10);
    }
  } else {
    inputValue = value;
  }

  updateFormData(name, inputValue, key, index);
};
```

---

## üü° HIGH PRIORITY ISSUES

### Data Quality & Consistency

#### 7. No Naming Convention Enforcement (HIGH)

**Repository:** rec_to_nwb_yaml_creator
**Impact:** Database inconsistency, file system errors

**Problem:** Critical identifiers (subject_id, animal names, task names) accept any characters including:

- Special characters: `!@#$%^&*()`
- Whitespace: `"my animal"`
- Unicode: `üê≠mouse1`
- Path separators: `animal/data`

**Database Impact:**

```sql
-- Inconsistent naming in database:
SELECT DISTINCT subject_id FROM experiments;
-- Results:
-- "Mouse1"
-- "mouse1"
-- "mouse_1"
-- " mouse1 "
-- "Mouse-1"
```

**Fix - Add Validation Pattern:**

```javascript
// In utils.js
export const IDENTIFIER_PATTERN = /^[a-zA-Z0-9_-]+$/;
export const IDENTIFIER_ERROR_MSG = "Use only letters, numbers, underscores, and hyphens";

export const validateIdentifier = (value, fieldName) => {
  const trimmed = value.trim();

  if (trimmed !== value) {
    return {
      valid: false,
      error: `${fieldName} has leading/trailing whitespace`,
      suggestion: trimmed
    };
  }

  if (!IDENTIFIER_PATTERN.test(trimmed)) {
    return {
      valid: false,
      error: `${fieldName} contains invalid characters. ${IDENTIFIER_ERROR_MSG}`,
      suggestion: trimmed.replace(/[^a-zA-Z0-9_-]/g, '_')
    };
  }

  return { valid: true, value: trimmed };
};

// Usage:
<InputElement
  id="subject-subjectId"
  name="subject_id"
  pattern="[a-zA-Z0-9_-]+"
  title="Use only letters, numbers, underscores, and hyphens"
  onBlur={(e) => {
    const validation = validateIdentifier(e.target.value, 'Subject ID');
    if (!validation.valid) {
      showCustomValidityError(e.target, validation.error);
      if (validation.suggestion) {
        console.log(`Suggestion: "${validation.suggestion}"`);
      }
    } else {
      onBlur(e, { key: 'subject' });
    }
  }}
/>
```

**Recommended Naming Convention:**

```markdown
## Naming Conventions for YAML Fields

To ensure database consistency and file system compatibility:

### Identifiers (subject_id, task_name, camera_name, etc.)
- **Format:** `[a-zA-Z0-9_-]+`
- **Rules:**
  - Only letters, numbers, underscores, hyphens
  - No spaces or special characters
  - Case-sensitive (but be consistent)
- **Good:** `mouse_123`, `CA1-tetrode`, `sleep_task`
- **Bad:** `mouse 123`, `CA1 tetrode!`, `sleep task`

### Best Practices
- Use lowercase for consistency: `mouse_123` not `Mouse_123`
- Use underscores to separate words: `linear_track` not `lineartrack`
- Be descriptive but concise: `sleep_box` not `sb` or `sleep_box_in_dark_room`
- Date format: YYYYMMDD (e.g., `20231215`)
```

---

#### 8. No Empty Channel Map Warning (HIGH)

**Repository:** rec_to_nwb_yaml_creator
**Location:** `src/ntrode/ChannelMap.jsx`

**Problem:** Users can set all channels to `-1` (empty), creating valid-but-useless configurations.

**Fix:**

```javascript
const validateChannelMap = (ntrodeMap) => {
  const validChannels = Object.values(ntrodeMap.map).filter(ch => ch !== -1);

  if (validChannels.length === 0) {
    return {
      valid: false,
      error: `Ntrode ${ntrodeMap.ntrode_id} has no valid channel mappings. At least one channel must be mapped.`
    };
  }

  if (validChannels.length < Object.keys(ntrodeMap.map).length * 0.5) {
    return {
      valid: false,
      warning: `Ntrode ${ntrodeMap.ntrode_id} has ${validChannels.length}/${Object.keys(ntrodeMap.map).length} channels mapped. Is this intentional?`
    };
  }

  return { valid: true };
};
```

---

#### 9. Task Epoch References Can Break Silently (HIGH)

**Repository:** rec_to_nwb_yaml_creator
**Location:** `src/App.js:832-859`

**Problem:** useEffect silently clears deleted task epoch references:

```javascript
// User creates:
// - Task 1 with epochs [1, 2, 3]
// - Associated file referencing epoch 2
// - User deletes Task 1
// ‚Üí Associated file's epoch reference set to '' silently
// ‚Üí User doesn't notice until reviewing exported YAML
```

**Fix:**

```javascript
useEffect(() => {
  const taskEpochs = [...new Set(
    formData.tasks.map(task => task.task_epochs).flat().sort()
  )];

  const warnings = [];

  // Check associated_files
  const updatedAssociatedFiles = formData.associated_files.map((file, i) => {
    if (file.task_epochs && !taskEpochs.includes(file.task_epochs)) {
      warnings.push({
        type: 'associated_file',
        index: i,
        name: file.name,
        epoch: file.task_epochs
      });
      return { ...file, task_epochs: '' };
    }
    return file;
  });

  // Check associated_video_files similarly...

  if (warnings.length > 0) {
    const message = "Some references were updated because task epochs were deleted:\n\n" +
      warnings.map(w =>
        `- ${w.type} "${w.name}" referenced epoch ${w.epoch} (now cleared)`
      ).join('\n') +
      "\n\nPlease review and reassign epochs as needed.";

    // Show modal or notification
    alert(message);
  }

  setFormData({
    ...formData,
    associated_files: updatedAssociatedFiles,
    // ... other updated arrays
  });
}, [formData.tasks]);  // Only trigger on task changes
```

---

### Integration & Synchronization

#### 10. Validation Timing Mismatch (HIGH)

**Repositories:** Both
**Impact:** Wasted user time

**Problem:**

```
Web App                          Python Package
   ‚Üì                                ‚Üì
AJV validation (Draft 7)         jsonschema (Draft 2020-12)
   ‚Üì PASSES                         ‚Üì
User downloads YAML              Load YAML
   ‚Üì                                ‚Üì
User runs conversion             Validation
                                    ‚Üì FAILS
                              "Invalid date format"
```

**Examples of Divergence:**

1. Date formats: AJV more permissive than jsonschema
2. Pattern matching: Slightly different regex engines
3. Array uniqueness: Different handling of object comparisons

**Fix - Add Pre-Export Python Validation:**

```javascript
// In App.js - before export
const validateWithPython = async (yamlContent) => {
  // Call validation endpoint
  const response = await fetch('/api/validate-yaml', {
    method: 'POST',
    body: yamlContent
  });

  if (!response.ok) {
    const errors = await response.json();
    throw new Error(
      "YAML validation failed:\n" +
      errors.map(e => `- ${e.message}`).join('\n')
    );
  }
};

// OR include Python jsonschema validator in web app build
// via pyodide or similar for client-side validation
```

**Better Fix - Use Same Validator:**

```bash
# Compile Python jsonschema to JavaScript
# OR
# Use JavaScript implementation that matches Python exactly
```

---

#### 11. No Version Compatibility Checks (HIGH)

**Repositories:** Both

**Problem:** No way to verify YAML from old web app version works with new Python package version.

**Fix - Add Version Fields:**

**YAML Schema:**

```json
{
  "properties": {
    "schema_version": {
      "type": "string",
      "pattern": "^\\d+\\.\\d+\\.\\d+$",
      "description": "Schema version (semver)"
    },
    "generated_by": {
      "type": "string",
      "description": "Generator name and version"
    }
  },
  "required": ["schema_version", ...]
}
```

**Web App:**

```javascript
const formData = {
  schema_version: "1.0.1",
  generated_by: `rec_to_nwb_yaml_creator v${packageJson.version}`,
  // ... rest of form data
};
```

**Python Package:**

```python
CURRENT_SCHEMA_VERSION = "1.0.1"
COMPATIBLE_VERSIONS = ["1.0.0", "1.0.1"]

def validate(metadata: dict) -> tuple:
    metadata_version = metadata.get("schema_version", "unknown")

    if metadata_version not in COMPATIBLE_VERSIONS:
        logger.warning(
            f"Schema version mismatch: metadata is {metadata_version}, "
            f"trodes_to_nwb supports {COMPATIBLE_VERSIONS}. "
            f"Some features may not work correctly."
        )

        if metadata_version == "unknown":
            raise ValueError(
                "YAML file missing schema_version field. "
                "Please regenerate using latest version of rec_to_nwb_yaml_creator."
            )
```

---

### Code Quality & Maintainability

#### 12. State Mutation in useEffect (HIGH)

**Repository:** rec_to_nwb_yaml_creator
**Location:** `src/App.js:842-856`

**Problem:** Violates React immutability:

```javascript
useEffect(() => {
  for (i = 0; i < formData.associated_files.length; i += 1) {
    formData.associated_files[i].task_epochs = '';  // MUTATION!
  }
  setFormData(formData);  // Setting mutated state
}, [formData]);
```

**Why This Is Bad:**

1. React may not detect changes (shallow comparison)
2. Previous renders see mutated data
3. Debugging time travel breaks
4. Unpredictable re-renders

**Fix:**

```javascript
useEffect(() => {
  const taskEpochs = [...new Set(
    formData.tasks.map(task => task.task_epochs).flat()
  )];

  // Create new objects, don't mutate
  const updatedAssociatedFiles = formData.associated_files.map(file => {
    if (!taskEpochs.includes(file.task_epochs)) {
      return { ...file, task_epochs: '' };  // New object
    }
    return file;  // Keep reference if unchanged
  });

  // Only update if something changed
  if (JSON.stringify(updatedAssociatedFiles) !== JSON.stringify(formData.associated_files)) {
    setFormData({
      ...formData,  // Shallow copy
      associated_files: updatedAssociatedFiles
    });
  }
}, [formData.tasks]);  // Depend only on tasks, not all formData
```

---

#### 13. Inconsistent Error Handling (HIGH)

**Repository:** trodes_to_nwb
**Locations:** Throughout

**Problem:** Three different error patterns:

```python
# Pattern 1: Raise immediately
raise ValueError("Error message")

# Pattern 2: Log and return None
logger.error("Error message")
return None

# Pattern 3: Log and continue
logger.info("ERROR: ...")
# continues execution
```

**Why This Is Bad:**

1. Callers don't know what to expect
2. Silent failures hard to debug
3. Errors discovered late in pipeline
4. Inconsistent user experience

**Fix - Establish Standard:**

```python
# ALWAYS raise exceptions for errors
# Use logging levels appropriately:
# - ERROR: Something failed, exception will be raised
# - WARNING: Something unexpected but continuing
# - INFO: Normal operation information

# Example:
def load_position_data(filename: Path) -> dict:
    """Load position tracking data.

    Raises:
        FileNotFoundError: If file doesn't exist
        ValueError: If file format is invalid
        IOError: If file cannot be read
    """
    if not filename.exists():
        logger.error(f"Position file not found: {filename}")
        raise FileNotFoundError(
            f"Position tracking file not found: {filename}\n"
            f"Expected: {filename.absolute()}"
        )

    try:
        data = _parse_position_file(filename)
    except ValueError as e:
        logger.error(f"Invalid position file format: {filename}")
        raise ValueError(
            f"Cannot parse position file {filename}: {e}\n"
            f"File may be corrupted or in wrong format."
        ) from e

    if len(data['timestamps']) == 0:
        logger.warning(f"Position file has no data: {filename}")
        # This is a warning, not an error - return empty dict
        return {}

    return data
```

---

## üü¢ MEDIUM PRIORITY ISSUES

### User Experience

#### 14. No Unsaved Changes Warning (MEDIUM)

**Repository:** rec_to_nwb_yaml_creator

**Fix:**

```javascript
const [formDirty, setFormDirty] = useState(false);

useEffect(() => {
  const handleBeforeUnload = (e) => {
    if (formDirty) {
      e.preventDefault();
      e.returnValue = 'You have unsaved changes. Are you sure you want to leave?';
      return e.returnValue;
    }
  };

  window.addEventListener('beforeunload', handleBeforeUnload);
  return () => window.removeEventListener('beforeunload', handleBeforeUnload);
}, [formDirty]);

// Set dirty flag on any form change
const updateFormData = (name, value, key, index) => {
  setFormDirty(true);
  // ... existing update logic
};
```

---

#### 15. Error Messages Use Internal Field Names (MEDIUM)

**Repository:** rec_to_nwb_yaml_creator

**Current:**

```
Error: electrode_groups-description-2 cannot be empty
```

**Better:**

```
Error: Electrode Group #3 - Description cannot be empty
```

**Fix:**

```javascript
const FIELD_LABELS = {
  'subject-subjectId': 'Subject ID',
  'electrode_groups-description': 'Electrode Group Description',
  'tasks-task_name': 'Task Name',
  // ... etc
};

const getFriendlyFieldName = (id) => {
  // Extract base field name
  const parts = id.split('-');
  const key = parts.slice(0, 2).join('-');
  const index = parts.length > 2 ? parseInt(parts[parts.length - 1]) : null;

  const label = FIELD_LABELS[key] || titleCase(key.replace('-', ' '));

  if (index !== null) {
    return `${label} #${index + 1}`;
  }
  return label;
};

// Usage in showErrorMessage:
const element = document.querySelector(`#${id}`);
const friendlyName = getFriendlyFieldName(id);
window.alert(`${friendlyName} - ${errorMessage}`);
```

---

#### 16. No Progress Indicators (MEDIUM)

**Repository:** trodes_to_nwb

**Problem:** Long operations (hours) with no feedback. Users kill process thinking it's hung.

**Fix:**

```python
from tqdm import tqdm
import logging

class TqdmLoggingHandler(logging.Handler):
    """Logging handler that plays nicely with tqdm progress bars."""
    def emit(self, record):
        try:
            msg = self.format(record)
            tqdm.write(msg)
        except Exception:
            self.handleError(record)

# In convert.py
def _create_nwb(...):
    # Setup progress tracking
    total_steps = 10  # Estimate steps
    with tqdm(total=total_steps, desc=f"Converting {session[1]}{session[0]}") as pbar:
        pbar.set_postfix_str("Loading metadata")
        metadata, device_metadata = load_metadata(...)
        pbar.update(1)

        pbar.set_postfix_str("Reading hardware config")
        rec_header = read_header(...)
        pbar.update(1)

        pbar.set_postfix_str("Processing ephys data")
        add_raw_ephys(...)
        pbar.update(3)

        # ... etc
```

---

### Data Validation

#### 17. No Coordinate Range Validation (MEDIUM)

**Repository:** rec_to_nwb_yaml_creator

**Problem:** Users can enter unrealistic coordinates:

```yaml
electrode_groups:
  - targeted_x: 999999  # 1000 km?
    targeted_y: -500000
    targeted_z: 0.00001  # 10nm?
    units: "mm"
```

**Fix:**

```javascript
const validateCoordinate = (value, unit, fieldName) => {
  const limits = {
    'mm': { min: -100, max: 100, typical: 10 },
    'Œºm': { min: -100000, max: 100000, typical: 10000 },
    'cm': { min: -10, max: 10, typical: 1 },
  };

  const limit = limits[unit] || limits['mm'];

  if (Math.abs(value) > limit.max) {
    return {
      valid: false,
      error: `${fieldName} (${value} ${unit}) exceeds typical range for brain coordinates (¬±${limit.max} ${unit})`
    };
  }

  if (Math.abs(value) > limit.typical) {
    return {
      valid: true,
      warning: `${fieldName} (${value} ${unit}) is larger than typical (¬±${limit.typical} ${unit}). Please verify.`
    };
  }

  return { valid: true };
};
```

---

#### 18. No Duplicate Detection in Comma-Separated Input (MEDIUM)

**Repository:** rec_to_nwb_yaml_creator
**Location:** `src/utils.js:47-73`

**Problem:**

```javascript
// User types: "1, 2, 3, 2, 4, 3"
// Result: [1, 2, 3, 4]  // Deduped silently
// User doesn't know 2 and 3 were duplicated
```

**Fix:**

```javascript
export const commaSeparatedStringToNumber = (stringSet) => {
  const numbers = stringSet
    .split(',')
    .map(n => n.trim())
    .filter(n => isInteger(n))
    .map(n => parseInt(n, 10));

  const unique = [...new Set(numbers)];

  if (numbers.length !== unique.length) {
    const duplicates = numbers.filter((n, i) => numbers.indexOf(n) !== i);
    console.warn(`Duplicate values removed: ${duplicates.join(', ')}`);
    // Could show toast notification
  }

  return unique.sort();
};
```

---

### Performance & Memory

#### 19. LazyTimestampArray Memory Explosion Risk (MEDIUM)

**Repository:** trodes_to_nwb
**Location:** `src/trodes_to_nwb/lazy_timestamp_array.py:288`

**Problem:** `__array__()` can load 600GB+ into memory without warning.

**Fix:**

```python
def __array__(self) -> np.ndarray:
    """Convert to numpy array - WARNING: Loads all timestamps!

    Raises:
        MemoryError: If array too large for available RAM
    """
    import psutil

    estimated_gb = self.nbytes / (1024**3)
    available_gb = psutil.virtual_memory().available / (1024**3)

    if estimated_gb > available_gb * 0.5:
        raise MemoryError(
            f"Cannot load timestamp array into memory:\n"
            f"  Required: {estimated_gb:.1f} GB\n"
            f"  Available: {available_gb:.1f} GB\n"
            f"  Duration: {self.duration_seconds / 3600:.1f} hours\n\n"
            f"Use lazy indexing instead:\n"
            f"  timestamps[start:stop]  # Load slice\n"
            f"  timestamps[::1000]      # Sample every 1000th"
        )

    logger.warning(
        f"Loading {estimated_gb:.1f} GB timestamp array into memory. "
        f"This may take several minutes..."
    )
    return self[:]
```

---

## üìã RECOMMENDATIONS FOR DATA CONSISTENCY

### Enforce Naming Standards

To ensure database consistency and eliminate naming variability:

#### 1. Standardized Identifiers

**Implement in Web App:**

```javascript
// Standard naming rules
const NAMING_RULES = {
  subject_id: {
    pattern: /^[a-z][a-z0-9_]*$/,
    description: "Lowercase letters, numbers, underscores. Must start with letter.",
    examples: ["mouse_001", "rat_24b", "subject_abc"],
    maxLength: 50
  },
  task_name: {
    pattern: /^[a-z][a-z0-9_]*$/,
    description: "Lowercase task identifier",
    examples: ["sleep", "linear_track", "open_field"],
    maxLength: 30
  },
  experimenter_name: {
    pattern: /^[A-Z][a-z]+, [A-Z][a-z]+$/,
    description: "LastName, FirstName",
    examples: ["Smith, John", "Doe, Jane"],
    maxLength: 100
  },
  camera_name: {
    pattern: /^[a-z][a-z0-9_]*$/,
    description: "Lowercase camera identifier",
    examples: ["overhead", "side_view", "camera_1"],
    maxLength: 30
  }
};

// Validation helper
const validateNaming = (value, fieldType) => {
  const rule = NAMING_RULES[fieldType];
  if (!rule) return { valid: true };

  if (value.length > rule.maxLength) {
    return {
      valid: false,
      error: `Maximum length is ${rule.maxLength} characters`,
      suggestion: value.substring(0, rule.maxLength)
    };
  }

  if (!rule.pattern.test(value)) {
    return {
      valid: false,
      error: rule.description,
      examples: rule.examples
    };
  }

  return { valid: true };
};
```

#### 2. Auto-Suggest Corrections

```javascript
const suggestCorrection = (value, fieldType) => {
  const rule = NAMING_RULES[fieldType];
  if (!rule) return value;

  let suggested = value;

  // Common corrections
  suggested = suggested.trim();
  suggested = suggested.toLowerCase();  // Most fields lowercase
  suggested = suggested.replace(/\s+/g, '_');  // Spaces to underscores
  suggested = suggested.replace(/[^a-z0-9_]/g, '');  // Remove invalid chars

  // Ensure starts with letter
  if (!/^[a-z]/.test(suggested)) {
    suggested = 'x_' + suggested;
  }

  return suggested;
};

// Usage in form:
<InputElement
  id="subject-subjectId"
  name="subject_id"
  onBlur={(e) => {
    const validation = validateNaming(e.target.value, 'subject_id');
    if (!validation.valid) {
      const suggestion = suggestCorrection(e.target.value, 'subject_id');
      const message = `${validation.error}\n\nSuggestion: "${suggestion}"\n\nExamples: ${validation.examples.join(', ')}`;

      if (window.confirm(message + '\n\nUse suggestion?')) {
        e.target.value = suggestion;
        updateFormData('subject_id', suggestion, 'subject');
      }
    }
  }}
/>
```

#### 3. Controlled Vocabularies for Common Fields

**Implement Dropdown with Custom Option:**

```javascript
const COMMON_TASKS = [
  'sleep',
  'linear_track',
  'open_field',
  'w_track',
  't_maze',
  'barnes_maze',
  'object_recognition'
];

const COMMON_LOCATIONS = [
  'ca1', 'ca2', 'ca3',
  'dentate_gyrus',
  'medial_entorhinal_cortex',
  'lateral_entorhinal_cortex',
  'prefrontal_cortex',
  'motor_cortex'
];

// In form:
<DataListElement
  id="tasks-task_name"
  name="task_name"
  dataItems={COMMON_TASKS}
  placeholder="Select or type custom task name"
  onBlur={(e) => {
    const value = e.target.value;
    const validation = validateNaming(value, 'task_name');
    if (!validation.valid) {
      showCustomValidityError(e.target, validation.error);
    }
  }}
/>
```

---

### Database Schema Recommendations

To support the YAML data:

```sql
-- Example schema for experiments database
CREATE TABLE experiments (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,  -- From YYYYMMDD
    subject_id VARCHAR(50) NOT NULL,  -- Enforced lowercase
    session_id VARCHAR(50) NOT NULL,
    experimenter_name VARCHAR(100)[],  -- Array
    institution VARCHAR(200) NOT NULL,
    lab VARCHAR(100) NOT NULL,
    nwb_file_path TEXT,
    created_at TIMESTAMP DEFAULT NOW(),

    -- Constraints for data quality
    CONSTRAINT chk_subject_id_format
        CHECK (subject_id ~ '^[a-z][a-z0-9_]*$'),
    CONSTRAINT chk_session_id_format
        CHECK (session_id ~ '^[a-z0-9_-]+$'),

    UNIQUE(date, subject_id, session_id)
);

CREATE TABLE tasks (
    id SERIAL PRIMARY KEY,
    experiment_id INTEGER REFERENCES experiments(id),
    task_name VARCHAR(30) NOT NULL,  -- Enforced lowercase
    task_description TEXT,
    task_environment VARCHAR(100),
    epochs INTEGER[],

    CONSTRAINT chk_task_name_format
        CHECK (task_name ~ '^[a-z][a-z0-9_]*$')
);

CREATE TABLE electrode_groups (
    id SERIAL PRIMARY KEY,
    experiment_id INTEGER REFERENCES experiments(id),
    electrode_group_id INTEGER NOT NULL,
    device_type VARCHAR(100) NOT NULL,
    location VARCHAR(100),  -- Use controlled vocabulary
    num_electrodes INTEGER,

    -- Ensure device_type matches known types
    CONSTRAINT chk_device_type CHECK (
        device_type IN (
            'tetrode_12.5',
            'A1x32-6mm-50-177-H32_21mm',
            '128c-4s8mm6cm-20um-40um-sl',
            -- ... all valid types
        )
    )
);

-- Validation query to check for inconsistent naming:
SELECT
    'subject_id' as field,
    subject_id as value,
    COUNT(*) as occurrences,
    ARRAY_AGG(DISTINCT LOWER(subject_id)) as variations
FROM experiments
GROUP BY subject_id
HAVING COUNT(DISTINCT LOWER(subject_id)) > 1;

-- This query finds cases like 'Mouse1', 'mouse1', 'MOUSE1' used inconsistently
```

---

## üéØ IMPLEMENTATION ROADMAP

### Week 1: Critical Fixes (Immediate)

- [ ] **Fix date_of_birth corruption bug** (Issue #1) - 2 hours
- [ ] **Implement schema sync CI check** (Issue #2) - 4 hours
- [ ] **Add progressive validation UI** (Issue #3) - 8 hours
- [ ] **Improve device type error messages** (Issue #4) - 2 hours
- [ ] **Add channel map validation** (Issue #5) - 4 hours
- [ ] **Fix camera ID parsing** (Issue #6) - 1 hour

**Total:** ~3 days

### Week 2: High Priority Data Quality (Important)

- [ ] **Enforce naming conventions** (Issue #7) - 6 hours
- [ ] **Add empty channel map warning** (Issue #8) - 2 hours
- [ ] **Fix task epoch reference handling** (Issue #9) - 4 hours
- [ ] **Add pre-export validation** (Issue #10) - 4 hours
- [ ] **Implement version compatibility** (Issue #11) - 4 hours
- [ ] **Fix React state mutation** (Issue #12) - 2 hours

**Total:** ~4 days

### Week 3: Code Quality & UX (Refinement)

- [ ] **Standardize error handling** (Issue #13) - 6 hours
- [ ] **Add unsaved changes warning** (Issue #14) - 2 hours
- [ ] **Improve error messages** (Issue #15) - 4 hours
- [ ] **Add progress indicators** (Issue #16) - 6 hours
- [ ] **Add coordinate validation** (Issue #17) - 2 hours
- [ ] **Fix duplicate detection** (Issue #18) - 2 hours

**Total:** ~4 days

### Week 4: Testing & Documentation (Stabilization)

- [ ] **Add integration tests** - 8 hours
- [ ] **Create error reference docs** - 4 hours
- [ ] **Add naming convention docs** - 2 hours
- [ ] **Update CLAUDE.md files** - 2 hours
- [ ] **Create video tutorials** - 8 hours

**Total:** ~3 days

### Ongoing: Maintenance

- [ ] Monitor schema sync
- [ ] Review user error reports
- [ ] Update device type lists
- [ ] Database consistency checks
- [ ] Performance optimization

---

## üìä TESTING STRATEGY

### Unit Tests Needed

**rec_to_nwb_yaml_creator:**

```javascript
// Test validation functions
describe('validateIdentifier', () => {
  test('accepts valid identifiers', () => {
    expect(validateIdentifier('mouse_001', 'Subject ID').valid).toBe(true);
  });

  test('rejects special characters', () => {
    expect(validateIdentifier('mouse@001', 'Subject ID').valid).toBe(false);
  });

  test('suggests corrections', () => {
    const result = validateIdentifier('Mouse 001!', 'Subject ID');
    expect(result.suggestion).toBe('mouse_001');
  });
});

// Test state management
describe('updateFormData', () => {
  test('maintains immutability', () => {
    const originalData = { subject: { id: 1 } };
    const updated = updateFormData('id', 2, 'subject');
    expect(originalData.subject.id).toBe(1);  // Unchanged
    expect(updated.subject.id).toBe(2);
  });
});

// Test channel map generation
describe('nTrodeMapSelected', () => {
  test('generates correct channel count', () => {
    const result = nTrodeMapSelected('tetrode_12.5', 0);
    expect(Object.keys(result.map)).toHaveLength(4);
  });

  test('handles duplicate electrode group IDs', () => {
    expect(() => {
      nTrodeMapSelected('tetrode_12.5', 0);  // ID 0
      nTrodeMapSelected('tetrode_12.5', 0);  // ID 0 again
    }).toThrow('duplicate');
  });
});
```

**trodes_to_nwb:**

```python
# Test validation
def test_validate_detects_missing_required_fields():
    metadata = {}
    is_valid, errors = validate(metadata)
    assert not is_valid
    assert 'experimenter_name' in str(errors)

def test_validate_rejects_invalid_device_type():
    metadata = basic_metadata.copy()
    metadata['electrode_groups'][0]['device_type'] = 'nonexistent_probe'

    with pytest.raises(ValueError, match='Unknown device_type'):
        add_electrode_groups(nwbfile, metadata, probe_metadata, ...)

def test_channel_map_validation_detects_duplicates():
    metadata = basic_metadata.copy()
    # Create duplicate mapping
    metadata['ntrode_electrode_group_channel_map'][0]['map'] = {
        '0': 5,
        '1': 5,  # Duplicate!
        '2': 6,
        '3': 7
    }

    with pytest.raises(ValueError, match='mapped multiple times'):
        make_hw_channel_map(metadata, rec_header)

# Test error messages
def test_missing_probe_metadata_error_is_helpful():
    try:
        # Trigger error
        pass
    except ValueError as e:
        error_msg = str(e)
        assert 'Available probe types:' in error_msg
        assert 'tetrode_12.5' in error_msg  # Lists available types
```

### Integration Tests

```python
def test_end_to_end_conversion():
    """Test full pipeline from YAML to NWB."""
    # 1. Generate YAML from web app (simulate)
    yaml_content = generate_test_yaml(
        subject_id='test_mouse_001',
        device_type='tetrode_12.5',
        date='20231215'
    )

    # 2. Validate YAML
    metadata = yaml.safe_load(yaml_content)
    is_valid, errors = validate(metadata)
    assert is_valid, f"YAML validation failed: {errors}"

    # 3. Create test .rec file
    create_test_rec_file(
        path='test_data/20231215_test_mouse_001_01_a1.rec',
        ntrodes=1,
        channels_per_ntrode=4,
        duration_seconds=60
    )

    # 4. Run conversion
    create_nwbs(
        path='test_data',
        output_dir='test_output'
    )

    # 5. Validate NWB file
    nwb_path = 'test_output/test_mouse_00120231215.nwb'
    assert os.path.exists(nwb_path)

    with NWBHDF5IO(nwb_path, 'r') as io:
        nwbfile = io.read()
        assert nwbfile.subject.subject_id == 'test_mouse_001'
        assert len(nwbfile.electrodes) == 4

    # 6. Run NWB Inspector
    from nwbinspector import inspect_nwbfile, Importance
    messages = list(inspect_nwbfile(nwb_path))
    critical_errors = [m for m in messages if m.importance == Importance.CRITICAL]
    assert len(critical_errors) == 0, f"Critical NWB errors: {critical_errors}"
```

### User Acceptance Tests

```gherkin
Feature: YAML Generation with Data Quality
  As a neuroscientist
  I want to create valid metadata files
  So that my data converts without errors

Scenario: Subject ID follows naming convention
  Given I am on the Subject Information section
  When I enter "Mouse 123!" in the Subject ID field
  Then I should see an error "Use only letters, numbers, underscores, and hyphens"
  And I should see a suggestion "mouse_123"

Scenario: Duplicate electrode group IDs prevented
  Given I have created electrode group with ID 0
  When I try to create another electrode group with ID 0
  Then I should see an error "Electrode group ID 0 already exists"
  And the ID field should be highlighted in red

Scenario: Device type matches available probes
  Given I select device type "custom_probe"
  And "custom_probe" is not in the trodes_to_nwb probe list
  When I generate the YAML file
  Then I should see a warning "Device type 'custom_probe' may not be supported"
  And I should see a list of supported device types

Scenario: Progressive validation shows completion status
  Given I am filling out the form
  Then I should see section completion indicators
  And completed sections should show a green checkmark
  And incomplete sections should show a warning icon
  And I should see overall completion percentage
```

---

## üîç MONITORING & METRICS

### Key Metrics to Track

```javascript
// In web app - analytics tracking
const trackValidationError = (errorType, fieldName, errorMessage) => {
  analytics.track('Validation Error', {
    errorType,
    fieldName,
    errorMessage,
    timestamp: new Date().toISOString()
  });
};

// Track common errors to identify UX improvements needed
const trackYAMLExport = (metadata) => {
  analytics.track('YAML Exported', {
    num_electrode_groups: metadata.electrode_groups.length,
    num_tasks: metadata.tasks.length,
    device_types: metadata.electrode_groups.map(g => g.device_type),
    has_optogenetics: metadata.opto_excitation_source.length > 0,
    schema_version: metadata.schema_version
  });
};
```

```python
# In Python package - log metrics
class ConversionMetrics:
    def __init__(self):
        self.conversion_time = 0
        self.file_size_gb = 0
        self.num_electrodes = 0
        self.duration_hours = 0
        self.warnings = []
        self.errors = []

    def log_to_file(self, session_name: str):
        """Log metrics for analysis."""
        metrics = {
            'session': session_name,
            'timestamp': datetime.now().isoformat(),
            'conversion_time_seconds': self.conversion_time,
            'file_size_gb': self.file_size_gb,
            'num_electrodes': self.num_electrodes,
            'duration_hours': self.duration_hours,
            'warnings_count': len(self.warnings),
            'errors_count': len(self.errors)
        }

        # Append to metrics log
        with open('conversion_metrics.jsonl', 'a') as f:
            f.write(json.dumps(metrics) + '\n')
```

### Dashboard Queries

```sql
-- Most common validation errors
SELECT
    error_type,
    field_name,
    COUNT(*) as occurrences,
    COUNT(DISTINCT user_id) as affected_users
FROM validation_errors
WHERE created_at > NOW() - INTERVAL '30 days'
GROUP BY error_type, field_name
ORDER BY occurrences DESC
LIMIT 20;

-- Subject ID naming patterns
SELECT
    CASE
        WHEN subject_id ~ '^[a-z][a-z0-9_]*$' THEN 'valid'
        WHEN subject_id ~ '^[A-Z]' THEN 'uppercase_start'
        WHEN subject_id ~ '\s' THEN 'contains_spaces'
        WHEN subject_id ~ '[^a-zA-Z0-9_]' THEN 'special_chars'
        ELSE 'other'
    END as pattern,
    COUNT(*) as count
FROM experiments
GROUP BY pattern;

-- Conversion success rate
SELECT
    DATE(created_at) as date,
    COUNT(*) as total_attempts,
    SUM(CASE WHEN success THEN 1 ELSE 0 END) as successful,
    ROUND(100.0 * SUM(CASE WHEN success THEN 1 ELSE 0 END) / COUNT(*), 2) as success_rate
FROM conversion_logs
WHERE created_at > NOW() - INTERVAL '30 days'
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

---

## üìö DOCUMENTATION IMPROVEMENTS NEEDED

### 1. User Guide: "How to Avoid Common Errors"

```markdown
# Common Mistakes and How to Avoid Them

## 1. Subject ID Naming
‚ùå **Wrong:**
- "Mouse 123" (contains space)
- "mouse#1" (special character)
- "MOUSE_001" (uppercase)

‚úÖ **Correct:**
- "mouse_123"
- "m001"
- "subject_abc"

**Rule:** Use only lowercase letters, numbers, and underscores. Start with a letter.

## 2. Electrode Group IDs
‚ùå **Wrong:**
- Using same ID for multiple groups
- Skipping numbers (0, 1, 5, 6)
- Starting from 1 instead of 0

‚úÖ **Correct:**
- Sequential: 0, 1, 2, 3
- Unique: No duplicates
- Starting from 0

## 3. Device Types
‚ùå **Wrong:**
- Typing custom name: "my_custom_probe"
- Typo: "tetrode12.5" (missing underscore)
- Using old name: "tetrode" (incomplete)

‚úÖ **Correct:**
- Select from dropdown
- Exact match: "tetrode_12.5"
- Check trodes_to_nwb for supported types

## 4. Task Epochs
‚ùå **Wrong:**
- Deleting task without updating references
- Using non-integer epochs: "1.5"
- Duplicate epoch numbers in same task

‚úÖ **Correct:**
- Check "Associated Files" before deleting tasks
- Use whole numbers: 1, 2, 3
- Each epoch appears once per task
```

### 2. Error Reference Guide

```markdown
# Error Messages Reference

## YAML Creator Errors

### "Electrode group ID X already exists"
**Cause:** Attempted to create duplicate electrode group ID

**Fix:**
1. Check existing electrode groups
2. Use next available ID (shown in UI)
3. Or delete duplicate group

### "Channel count mismatch"
**Cause:** YAML channel map doesn't match device type

**Fix:**
1. Delete electrode group
2. Recreate and select correct device type
3. System will auto-generate correct channel map

## Conversion Errors

### "No probe metadata found for {device_type}"
**Cause:** Device type in YAML not recognized

**Fix:**
1. Check available types: `ls trodes_to_nwb/device_metadata/probe_metadata/`
2. Update YAML to use valid type
3. Or add custom probe metadata file

### "Hardware channel mismatch for ntrode X"
**Cause:** YAML configuration doesn't match .rec file

**Fix:**
1. Regenerate YAML from web app
2. Ensure using latest hardware configuration
3. Check .rec file header: `python -c "from trodes_to_nwb.convert_rec_header import read_header; print(read_header('file.rec'))"`

### "Date of birth validation failed"
**Cause:** Invalid date format

**Fix:**
1. Use YYYY-MM-DD format
2. Check date is not in future
3. Web app should enforce this - report bug if you see this
```

### 3. Developer Guide: "Adding New Device Types"

```markdown
# Adding New Device/Probe Types

## Checklist

- [ ] Create probe metadata YAML in trodes_to_nwb
- [ ] Add device type to web app dropdown
- [ ] Add channel mapping logic
- [ ] Test end-to-end conversion
- [ ] Update documentation

## Step 1: Create Probe Metadata

**File:** `trodes_to_nwb/src/trodes_to_nwb/device_metadata/probe_metadata/new_probe.yml`

```yaml
probe_type: "new_probe_32ch"  # Must match device_type in web app
manufacturer: "Manufacturer Name"
probe_description: "32-channel probe description"
units: "um"
num_shanks: 2

shanks:
  - shank_id: 0
    electrodes:
      - id: 0
        rel_x: 0.0
        rel_y: 0.0
        rel_z: 0.0
        contact_size: 15.0
      - id: 1
        rel_x: 20.0
        rel_y: 0.0
        rel_z: 0.0
        contact_size: 15.0
      # ... 14 more electrodes for shank 0

  - shank_id: 1
    electrodes:
      # ... 16 electrodes for shank 1
```

## Step 2: Update Web App

**File:** `rec_to_nwb_yaml_creator/src/valueList.js`

```javascript
export const deviceTypes = () => {
  return [
    // ... existing types
    'new_probe_32ch',  // Add new type
  ];
};
```

**File:** `rec_to_nwb_yaml_creator/src/ntrode/deviceTypes.js`

```javascript
export const deviceTypeMap = (deviceType) => {
  // ... existing cases

  case 'new_probe_32ch':
    defaults = Array.from({length: 16}, (_, i) => i);  // 16 channels per shank
    break;
};

export const getShankCount = (deviceType) => {
  // ... existing cases

  case 'new_probe_32ch':
    return 2;  // 2 shanks
};
```

## Step 3: Test

```bash
# 1. Test in web app
npm run start
# Create electrode group with new device type
# Verify channel map generated correctly

# 2. Generate test YAML
# Export YAML file

# 3. Test conversion
cd ../trodes_to_nwb
python -c "
from trodes_to_nwb import create_nwbs
create_nwbs('test_data', output_dir='test_output')
"

# 4. Verify NWB file
python -c "
from pynwb import NWBHDF5IO
with NWBHDF5IO('test_output/test.nwb', 'r') as io:
    nwbfile = io.read()
    print(f'Electrodes: {len(nwbfile.electrodes)}')
    print(nwbfile.electrodes.to_dataframe())
"
```

## Step 4: Document

Update both repositories:

- Add to CLAUDE.md
- Add to README.md supported devices list
- Add example YAML to docs/

```

---

## ‚úÖ CONCLUSION

### Summary of Critical Issues

| Priority | Issue | Impact | Effort | Status |
|----------|-------|--------|--------|--------|
| üî¥ P0 | Date of birth corruption | Data corruption | 1 hour | **MUST FIX NOW** |
| üî¥ P0 | Schema synchronization | Silent failures | 4 hours | **MUST FIX NOW** |
| üî¥ P0 | Silent validation failures | User frustration | 8 hours | **MUST FIX NOW** |
| üî¥ P0 | Device type mismatches | Conversion failures | 2 hours | **MUST FIX NOW** |
| üî¥ P0 | Hardware channel validation | Data corruption | 4 hours | **MUST FIX NOW** |
| üî¥ P0 | Type coercion bugs | Invalid data accepted | 2 hours | **MUST FIX NOW** |
| üü° P1 | Naming conventions | Database inconsistency | 6 hours | Week 2 |
| üü° P1 | Error handling consistency | Developer confusion | 6 hours | Week 2 |
| üü¢ P2 | Progress indicators | User experience | 6 hours | Week 3 |
| üü¢ P2 | Documentation | User support | 16 hours | Week 4 |

### Risk Assessment

**Before Fixes:**
- üî¥ High risk of data corruption
- üî¥ High risk of conversion failures
- üü° Moderate database inconsistency
- üü° Poor error recovery

**After Fixes:**
- üü¢ Low risk of data corruption
- üü¢ Low risk of conversion failures
- üü¢ Good database consistency
- üü¢ Clear error messages and recovery

### Next Steps

1. **Immediate (This Week):**
   - Fix date_of_birth bug (trodes_to_nwb)
   - Add schema sync CI check
   - Implement progressive validation (web app)

2. **Short Term (Next 2 Weeks):**
   - Enforce naming conventions
   - Standardize error handling
   - Add version compatibility

3. **Medium Term (Next Month):**
   - Comprehensive testing
   - Documentation overhaul
   - User training materials

4. **Long Term (Ongoing):**
   - Monitor error rates
   - Collect user feedback
   - Database consistency audits

---

**Review Prepared By:** Senior Developer (AI Code Review)
**Date:** 2025-01-23
**Recommended Action:** Address all P0 issues immediately, schedule P1 for next sprint
